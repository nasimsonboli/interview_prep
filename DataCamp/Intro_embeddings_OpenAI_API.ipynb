{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cacbc595-6ee8-44c3-9353-ea17dd8441ba",
   "metadata": {},
   "source": [
    "# 1. What are Embeddings?\n",
    "- Texts (words, phrases, entire documents) are represented in **numerical form**.\n",
    "- Embedding models **map text into a multi-dimensional vector space**. And the numbers outputted by the model are the text's location in that space.\n",
    "    - similar words are **mapped** closer together in that space, and dissimilar words are further away.\n",
    "- Embeddings allow **semantic meaning** to be captured from the text.\n",
    "    - Semantic meaning means: **context and intent behind text**\n",
    "- Most powerful use cases:\n",
    "    - **Search engines**\n",
    "        - traditional search engines use **keyword pattern recognition**. They might miss the true intent behind the searcher's query and might miss word variations (e.g., \"soft\" instead of \"comfortable\" or \"sneakers\" instead of \"shoes\").\n",
    "        - Semantic search engines use embeddings to better understand the intent and context behind search queries to return more relevant results. The search query would be passed to an embedding model to generate the numbers that are mapped onto a vector space, and the embedded results closest to it would be returned.\n",
    "    - **Recommendation systems**\n",
    "        - embeddings enable more sophisticated recommender systems. e.g., for a job post recommendation, using embeddings allows recommending jobs based on viewed job descriptions, and it allows semantically similar jobs to be recommended.\n",
    "    - **Classification**\n",
    "        - cluster observations, classify sentiment, and perform categorization based on the semantic similarity between texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fc8fa9-f1fb-4313-86f8-d8b446109e41",
   "metadata": {},
   "source": [
    "## How to use an OpenAI Embedding endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9e68bc1-3dc2-4eb1-ba5a-aa262376f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# instantiate an OPENAI client and pass it out API key\n",
    "client = OpenAI(api_key=\"????\")\n",
    "\n",
    "# to create a request, we call the create method on client.embeddings()\n",
    "# input can be a list of strings\n",
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    input=\"Embeddings are a numerical representation of text that can be used to measure the relatedness between two pieces of text.\"\n",
    ")\n",
    "\n",
    "# we call .model_dump() on the response\n",
    "response_dict = response.model_dump()\n",
    "print(response_dict)\n",
    "\n",
    "# The response from the API is long. The embedding model outputs 1536 numbers to represent this input string. \n",
    "# Having it in a dictionary makes it easier to dig into.\n",
    "# this will print all the embeddings\n",
    "print(response_dictp['data'][0]['embedding'])\n",
    "\n",
    "print(response_dict['usage']['total_tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15101829-d9c8-4f09-9147-a887d59e2dc7",
   "metadata": {},
   "source": [
    "## Investigating the vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eb08138-9368-426b-bf40-49d54d481aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [\n",
    "    {\"headline\": \"The Blues get promoted on the final day of the season!\", \"topic\": \"Sport\"},\n",
    "    {\"headline\": \"1.5 Billion Tune-in to the World Cup Final\", \"topic\": \"Sport\"},\n",
    "    {\"headline\": \"New Particle Discovered in CERN\", \"topic\": \"Science\"},\n",
    "    {\"headline\": \"Scientists make breakthrough discovery in renewable energy\", \"topic\": \"Sport\"}\n",
    "]\n",
    "\n",
    "# The goal\n",
    "# We will embed each headline's text and add it back into the headlines dictionary, stored under the embedding key.\n",
    "# therefore each article has {\"headline\": \"???\", \"topic\": \"...\", \"embedding\" = [?, ?, ?, ...]}\n",
    "\n",
    "headline_text = [article['headline'] for article in articles]\n",
    "\n",
    "# We can pass a list of lists to the input\n",
    "# create embedding for each article\n",
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    input=headline_text\n",
    ")\n",
    "\n",
    "# There will be one dictionary for every input instead of 1 dictionary\n",
    "response_dict = response.model_dump()\n",
    "\n",
    "# extract the embedding from response_dict and store it in articles\n",
    "for i, article in enumerate(articles):\n",
    "    articles['embedding'] = response_dict['data'][i]['embedding']\n",
    "\n",
    "# print the first two articles\n",
    "print(articles[:2])\n",
    "\n",
    "# print the first items and its description, embedding, etc.\n",
    "print(articles[0].items())\n",
    "\n",
    "# no matter the length of the input, OPENAI always returns 1536 numbers representing the semantic meaning of the headline, its position, or vector in the vector space\n",
    "len(articles[0]['embedding'])\n",
    "len(articles[5]['embedding'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f0b263-d2b1-480d-bd49-e65777dd2511",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction and t-SNE\n",
    "\n",
    "- We'll be using t-SNE (t-distributed Stochastic Neighbor Embedding) technique for dimensionality reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1147402-1b4c-4f28-90a7-d72ae29c6e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "# extract the embeddings\n",
    "embeddings = [article['embedding'] for article in articles]\n",
    "\n",
    "# create an instance of tsne\n",
    "    # n_components: the number of output dimensions \n",
    "    # perplexity: must be less than the number of data. The default is 30 for big data.\n",
    "tsne = TSNE(n_components=2, perplexity=3)\n",
    "\n",
    "# this will return the transformed embeddings in a Numpy array with n_components dimensions, which we can now visualize.\n",
    "embedding_2d = tsne.fit_transform(np.array(embeddings))\n",
    "\n",
    "# This will result in less information, so use with caution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6866cf98-4d8b-490c-acd4-705520290226",
   "metadata": {},
   "source": [
    "## Visualizing the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e4e084-d4e0-493b-87cc-394897480b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# first and second columns of the embeddings_2d array.\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1])\n",
    "\n",
    "topics = [article['topic'] for article in articles]\n",
    "for i, topic in enumerate(topics):\n",
    "    plt.annotate(topic, (embedding_2d[i, 0], embeddings_2d[i, 1]))\n",
    "\n",
    "plt.show()\n",
    "# similar articles with similar topics are closer together.\n",
    "# The model captured the semantic meaning of the headlines and mapped them based on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104067ae-5983-48c0-bf3d-c660beea7cd5",
   "metadata": {},
   "source": [
    "## Text Similarity\n",
    "- Calculate the similarity between texts using embeddings.\n",
    "- Recall that semantically similar texts are embedded more closely in the vector space.\n",
    "- This means that we can measure how semantically similar two pieces of text are by computing the **distance between vectors in the vector space**\n",
    "- Cosine Distance (1 - cos(a)) where a could be between [-1, 1] or [0, 1]\n",
    "    - so the distance could be between 0 and 2 (1 - (-1))\n",
    "    - Smaller numbers show higher similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d29b26c-576f-4017-b8eb-fc121dfc4ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "distance.cosine([0, 1], [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1192ecc4-a72c-4327-aad0-6f8e1faa9ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(texts):\n",
    "    response = client.embeddings.create(\n",
    "        model = \"text-embedding-3-small\",\n",
    "        input=texts\n",
    "    )\n",
    "    response_dict = response.model_dump()\n",
    "    return [data['embedding'] for data in response_dict['data']]\n",
    "\n",
    "print(create_embeddings([\"Python is the best\", \"R is the best\"]))\n",
    "\n",
    "# for a single list, make sure to zero-index the result.\n",
    "print(create_embeddings(\"This is awesome\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831ea961-1408-4df9-87e7-bed1104e7d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "search_text = \"computer\"\n",
    "search_embedding = create_embeddings(search_text)[0] # make sure to sero-index it if it is one input!!!!!\n",
    "\n",
    "# calculate the cosine between the embeddings of the headlines and embeddings of the query.\n",
    "distances = []\n",
    "for article in articles:\n",
    "    dist = distance.cosine(search_embeddings, article['embedding'])\n",
    "    distances.append(dist)\n",
    "\n",
    "# NumPy's argmin function returns the index of the smallest value in the distances list\n",
    "min_dist_ind = np.argmin(distances)\n",
    "\n",
    "# return its headline\n",
    "print(articles[min_dist_ind]['headline'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f64cd6-e441-477f-ab58-46f7fe38ec74",
   "metadata": {},
   "source": [
    "# 2. Embeddings for AI Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf01547-1032-4335-a22c-2c139ab7ceb5",
   "metadata": {},
   "source": [
    "## Semantic Search and enriched embeddings\n",
    "Semantic search engines use embeddings to return the **most semantically similar** results to a search query. \\\n",
    "There are three steps to semantic search:\n",
    "1. Embed the search query and other texts to compare against\n",
    "2. Compute the cosine distances between the embedded search query and other embedded texts\n",
    "3. Extract the text with the smallest cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97560cca-5a72-4bea-96f6-509e8a9db33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [\n",
    "    {\n",
    "        \"headline\": \"AI Breakthrough Enables Real-Time Language Translation Without Internet\",\n",
    "        \"topic\": \"Artificial Intelligence\",\n",
    "        \"keywords\": [\"AI\", \"machine learning\", \"language translation\", \"offline AI\", \"technology innovation\"]\n",
    "    },\n",
    "    {\n",
    "        \"headline\": \"Olympic Sprinter Sets New World Record in 100m Final\",\n",
    "        \"topic\": \"Sports\",\n",
    "        \"keywords\": [\"Olympics\", \"sprinting\", \"track and field\", \"world record\", \"athletics\"]\n",
    "    },\n",
    "    {\n",
    "    \"headline\": \"Climate Scientists Warn of Accelerating Ice Melt in Antarctica\",\n",
    "    \"topic\": \"Environment\",\n",
    "    \"keywords\": [\"climate change\", \"Antarctica\", \"ice melt\", \"global warming\", \"scientific research\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Combine the information of each article into a single string that reflects the information stored in each dictionary.\n",
    "# We use F-strings or formatted-string to return the desired string structure.\n",
    "# F-strings allow us to insert variables into strings without having to convert them into strings and concatenate them.\n",
    "# Pay attention that we use \"\"\" around the string.\n",
    "# join all the keywords with comma and space.\n",
    "\n",
    "def create_article_text(article):\n",
    "    return f\"\"\"\n",
    "            Headline: {article['headline']}\n",
    "            Topic: {article['topic']}\n",
    "            Keywords: {', '.join(article['keywords'])}\n",
    "            \"\"\"\n",
    "\n",
    "# calling the function on the final headline\n",
    "print(create_article_text(article[-1]))\n",
    "\n",
    "# Creating enriched embeddings for each article\n",
    "article_texts = [create_article_text(article) for article in articles]\n",
    "\n",
    "# create embeddings\n",
    "article_embeddings = create_embeddings(article_texts)\n",
    "print(article embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3944460-b14e-44ef-bb8b-b43b702518a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cosine distances\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def find_n_closest(query_vector, embeddings, n=3):\n",
    "    distances = []\n",
    "    for index, embedding in enumerate(embeddings):\n",
    "        dist = distance.cosine(query_vector, embedding)\n",
    "        distances.append({'distance':dist, \"index\":index})\n",
    "    \n",
    "    distances_sorted = sorted(distances, key=lambda x: x['distance']) # it accesses the 'distance' key for each dictionary\n",
    "\n",
    "    # return the closest n results\n",
    "    return distances_sorted[0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bca3d18-9cf3-48f1-acf2-9e8da3d3664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"AI\"\n",
    "query_vector = create_embedding(query_text)[0] # extract the embeddings by 0 indexing\n",
    "\n",
    "# find the 3 closest articles to this query\n",
    "hits = find_n_closest(query_vector, article_embeddings)\n",
    "\n",
    "for hit in hits:\n",
    "    # get the article based on the index\n",
    "    article = articles[hit['index']]\n",
    "    # get the headline now that we know the index\n",
    "    print(article['headline'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fccb4a-1892-4d18-959b-08c672009abe",
   "metadata": {},
   "source": [
    "## Recommendation Systems\n",
    "1. embed the potential recommendations and data points\n",
    "2. Calculate the cosine distance\n",
    "3. Recommend the closest items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64980a8-9347-477f-9393-f52d11f55fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume that we have the previous articles dictionary lis\n",
    "articles = [\n",
    "    {\n",
    "        \"headline\": \"AI Breakthrough Enables Real-Time Language Translation Without Internet\",\n",
    "        \"topic\": \"Artificial Intelligence\",\n",
    "        \"keywords\": [\"AI\", \"machine learning\", \"language translation\", \"offline AI\", \"technology innovation\"]\n",
    "    },\n",
    "    {\n",
    "        \"headline\": \"Olympic Sprinter Sets New World Record in 100m Final\",\n",
    "        \"topic\": \"Sports\",\n",
    "        \"keywords\": [\"Olympics\", \"sprinting\", \"track and field\", \"world record\", \"athletics\"]\n",
    "    },\n",
    "    {\n",
    "    \"headline\": \"Climate Scientists Warn of Accelerating Ice Melt in Antarctica\",\n",
    "    \"topic\": \"Environment\",\n",
    "    \"keywords\": [\"climate change\", \"Antarctica\", \"ice melt\", \"global warming\", \"scientific research\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# and a current article\n",
    "current_article = {\n",
    "    \"headline\": \"Cutting-Edge Hardware Accelerates the Next Wave of AI Innovation\",\n",
    "    \"topic\": \"Artificial Intelligence\",\n",
    "    \"keywords\": [\"AI\", \"computer hardware\", \"GPUs\", \"TPUs\", \"AI acceleration\", \"machine learning infrastructure\"]\n",
    "                }\n",
    "\n",
    "# combine the text together similar to the previous code. use create_article_text to\n",
    "article_texts = [create_article_text(article) for article in articles]\n",
    "current_article_text =  create_article_text(current_article)\n",
    "print(current_article_text)\n",
    "\n",
    "# create embeddings \n",
    "article_embeddings = create_embeddings(article_texts)\n",
    "current_article_embeddings = create_embeddings(current_article_text)[0] # zero indexing\n",
    "\n",
    "# find the nearest distances between the current article embedding and all the article embeddings, using the find_n_closest\n",
    "hits = find_n_closest(current_article_embeddings, article_embeddings)\n",
    "\n",
    "for hit in hits:\n",
    "    article = articles[hit['index']]\n",
    "    print(article['headline'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77fd30e-3ded-4cf0-9fb7-6ad44b07ff2b",
   "metadata": {},
   "source": [
    "## Recommendations on two data points\n",
    "let's consider that a user has visited 2 articles. To find the most similar vector to two vector spaces, \n",
    "- We'll combine the two vectors into 1 by **taking the mean**.\n",
    "- compute cosine distance\n",
    "- recommend the closest vector\n",
    "- recommend the nearest **unseen** article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd784c-b2e9-4389-b5a0-1961d53176f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_texts = [create_article_text(article) for article in user_history]\n",
    "history_embeddings = create_embeddings(history_texts)\n",
    "mean_history_embeddings = np.mean(history_embeddings, axis=0) # we can give it a list of texts\n",
    "\n",
    "# filter the articles to make sure the user hasn't seen them\n",
    "articles_filtered = [article for article in articles if article not in user_history]\n",
    "article_texts = [create_article_text(article) for article in articles_filtered]\n",
    "articles_embeddings = create_embeddings(article_texts)\n",
    "\n",
    "hits = find_n_closest(mean_history_embeddings, article_embeddings)\n",
    "\n",
    "for hit in hits:\n",
    "    article = articles_filtered[hit['index']]\n",
    "    print(article['headline'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34e575a-4bb1-4b68-bf7d-56606aff3740",
   "metadata": {},
   "source": [
    "## Embeddings for classification\n",
    "\n",
    "Assigning labels to items\n",
    "- categorization\n",
    "    - example: headline into topics (e.g. sports, tech, business, science, etc.)\n",
    "- sentiment analysis\n",
    "    - example: classifying reviews as positive or negative.\n",
    "\n",
    "We will use **zero-shot** classification here. The classification won't be based on labeled examples.\n",
    "\n",
    "Process:\n",
    "1. embed class descriptions (embed words such as science, tech, etc.)\n",
    "    - **limitation** if the class description lacks detail, the embeddings might make mistakes or misclassify. \n",
    "3. embed the item to classify.\n",
    "4. Compute cosine distances.\n",
    "5. Assign the article the most similar label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9547eaa6-e7de-41b9-a475-09a0142df4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\n",
    "    {\"label\": \"tech\"},\n",
    "    {\"label\": \"science\"},\n",
    "    {\"label\": \"sport\"},\n",
    "    {\"label\": \"business\"}\n",
    "]\n",
    "\n",
    "class_descriptions = [topic['label'] for topic in topics]\n",
    "class_embeddings = create_embeddings(class_description)\n",
    "\n",
    "# here is the article we want to classify\n",
    "article = {\n",
    "    \"headline\": \"Cutting-Edge Hardware Accelerates the Next Wave of AI Innovation\",\n",
    "    \"topic\": \"Artificial Intelligence\",\n",
    "    \"keywords\": [\"AI\", \"computer hardware\", \"GPUs\", \"TPUs\", \"AI acceleration\", \"machine learning infrastructure\"]\n",
    "                }\n",
    "\n",
    "article_text = create_article_text(article)\n",
    "article_embedding = create_embedding(article_text)\n",
    "\n",
    "# if we want to find 1 label, we modify the previous article\n",
    "def find_closest(query_vector, embeddings):\n",
    "    distances = []\n",
    "    for index, embedding in enumerate(embeddings):\n",
    "        dist = distance.cosine(query_vector, embedding)\n",
    "        distances.append({'distance':dist, 'index':index})\n",
    "    \n",
    "    # find the min distance\n",
    "    return min(distances, key=lambda x:x['distance'])\n",
    "\n",
    "\n",
    "# find the label\n",
    "for index, article in enumerate(articles):\n",
    "    # Find the closest distance and its index using find_closest()\n",
    "    closest = find_closest(article_embeddings[index], class_embeddings)\n",
    "    \n",
    "    # Subset labels/topics using the index from closest\n",
    "    label = topics[closest['index']]['label']\n",
    "    print(f'\"{review}\" was classified as {label}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986607a6-01d2-47b3-9944-d4d77f1a0854",
   "metadata": {},
   "source": [
    "- We add more descriptions to the class lables here to overcome the limitations of the previous method. Instead of label embeddings, we use description embeddings for each label this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "029aec35-3e02-486f-b5db-e2797f94304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\n",
    "    {\n",
    "        \"label\": \"tech\",\n",
    "        \"description\": \"Covers the latest developments in technology, including software, hardware, and innovations in AI.\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"science\",\n",
    "        \"description\": \"Focuses on discoveries, research, and advancements in fields such as biology, physics, and environmental science.\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"sport\",\n",
    "        \"description\": \"Includes news and updates about sporting events, athletes, competitions, and records.\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"business\",\n",
    "        \"description\": \"Reports on the economy, markets, companies, startups, and financial trends.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "class_descriptions = [topic['description'] for topic in topics]\n",
    "class_embeddings = create_embeddings(class_description)\n",
    "\n",
    "\n",
    "# the rest is the same as before\n",
    "# here is the article we want to classify\n",
    "article = {\n",
    "    \"headline\": \"Cutting-Edge Hardware Accelerates the Next Wave of AI Innovation\",\n",
    "    \"topic\": \"Artificial Intelligence\",\n",
    "    \"keywords\": [\"AI\", \"computer hardware\", \"GPUs\", \"TPUs\", \"AI acceleration\", \"machine learning infrastructure\"]\n",
    "                }\n",
    "\n",
    "article_text = create_article_text(article)\n",
    "article_embeddings = create_embedding(article_text)\n",
    "\n",
    "# if we want to find 1 label, we modify the previous article\n",
    "def find_closest(query_vector, embeddings):\n",
    "    distances = []\n",
    "    for index, embedding in enumerate(embeddings):\n",
    "        dist = distance.cosine(embedding, query_vector)\n",
    "        distances.append({'distance':dist, 'index':index})\n",
    "    \n",
    "    # find the min distance\n",
    "    return min(distances, key=lambda x:x['distance'])\n",
    "\n",
    "\n",
    "# find the label\n",
    "for index, article in enumerate(reviews):\n",
    "  closest = find_closest(article_embeddings[index], class_embeddings)\n",
    "  label = topics[closest['index']]['label']\n",
    "  print(f'\"{article}\" was classified as {label}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33128fa6-5555-41f2-805a-7a9ef27528c9",
   "metadata": {},
   "source": [
    "# 3. Vector Databases for embedding systems\n",
    "\n",
    "**limitation** of the current approach:\n",
    "- Loading all the embeddings **in the memory** can be impractical due to its size (1536 floats, around 13kB/embedding).\n",
    "- Recalculating the embeddings for each new query instead of storing them for later use is not efficient.\n",
    "- Calculating cosine distance for every embedding and sorting is **slow and scales linearly**.\n",
    "\n",
    "**Vector Databases** are better solutions that enable embeddings with larger datasets in production. \n",
    "- In this solution, the embedded documents are stored and queried from vector databases.\n",
    "- A query is sent from the application interface, embedded and used to query the embeddings in the database. This could be a semantic search query or data.\n",
    "- The results are returned to the users via the application interface.\n",
    "- The embedded documents are stored in the vector database, they don't have to be created with each query or stored in memory.\n",
    "- Due to the architecture of the database, the similarity is computed much more efficiently.\n",
    "- The majority of the vector databases are called **NoSQL** databases. NoSQL databases don't use tables like conventional SQL (relational databases). Their data can be structured in several ways to enable faster querying. Three NoSQL architectures are shown:\n",
    "    - key, value\n",
    "    - documents\n",
    "    - graph databases\n",
    "- Vector databases aren't only used for **storing the embeddings**; the **source texts** are also commonly stored. For vector databases that don't allow storing the source texts, source texts must be stored in a separate database and referenced with an ID. **Metadata** is also stored in the database, including IDs and external references, and additional data that could be useful for filtering the query results.\n",
    "    - **Avoid** storing the source texts as metadata. Metadata must be small to be practically useful. So, adding a large amount of text data will greatly degrade performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab4c429-4b49-4bb1-a8c6-b0bdbf359012",
   "metadata": {},
   "source": [
    "## Creating vector databases with ChromaDB\n",
    "- ChromaDB is a simple yet powerful vector database.\n",
    "- Two flavors:\n",
    "    - Local: great for development and prototyping. Everything happens inside Python.\n",
    "    - Client/Server mode: made for production. A ChromDB server is running in a separate process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea8e509-d4b1-43c3-ba8b-4027ba49605e",
   "metadata": {},
   "source": [
    "### connecting to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "988c6ee2-b5b7-4b57-909b-e50048713cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b633e1d9-5997-460c-b860-7ea17095aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "# data will be persisted to disk\n",
    "client = chromadb.PersistentClient(path=\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67997b8c-d893-49d9-b3ef-96ae3bab5ab6",
   "metadata": {},
   "source": [
    "### Add embeddings to the database\n",
    "- first create a collection.\n",
    "    - A collection is analogous to tables.\n",
    "- We need to pass the name of the collection and a function to create the embeddings.\n",
    "    - In Chroma or other vector databases, a default embedding function is used automatically, if one isn't specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "78e6e29d-5073-4317-ad60-e3c4c3c76046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc85eb38-8415-4a0c-ac8a-66646bd262c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.create_collection(\n",
    "    name=\"my_collection\",\n",
    "    embedding_function=OpenAIEmbeddingFunction(\n",
    "        model_name=\"text-embedding-3-small\",\n",
    "        api_key=\"Your_API_KEY\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6767912d-42d4-4046-bc47-c3d5d5a30d6b",
   "metadata": {},
   "source": [
    "### Listing all the collections in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "af68e643-5e51-41da-906f-3b2dc14f0e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d627f93f-1fce-41e5-acee-26d501bcf197",
   "metadata": {},
   "source": [
    "### Inserting Embeddings to the collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dbe4dd-a6a3-45d8-ab0c-74d7a4d6510e",
   "metadata": {},
   "source": [
    "#### Single Document\n",
    "- Chroma doesn't automatically generate **IDs** for these documents, so they **must** be specified.\n",
    "- Embeddings will be created automatically by the collection, since it's aware of the embedding function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b1c69d17-7d56-425f-a1e7-026cd8153ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(ids=[\"my-doc\"], documents=[\"This is the source text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7043f843-a4e9-4cc2-8e53-98c13441223b",
   "metadata": {},
   "source": [
    "#### Multiple Document\n",
    "- pass multiple ids and documents for multiple insertion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "038b90ad-b34a-45bb-a2ce-9fd576aab179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the embeddings will be created automatically when the texts are inserted.\n",
    "collection.add(ids=[\"my-doc-1\", \"my-doc-2\"], documents=[\"This is the document 1\", \"This is document 2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e112db-0394-4e67-851b-1433b7b6c4b2",
   "metadata": {},
   "source": [
    "### Inspecting a collection\n",
    "\n",
    "- **collection.count()** will return the total number of documents in the collection.\n",
    "- **collection.peek()** will return the first 10 items in the collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b59baf9-4d07-4872-ac56-8202f0c0b56f",
   "metadata": {},
   "source": [
    "### Retrieving items\n",
    "- **collection.get(id[\"s59\"])** retreiving particular items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07afa36-d3e5-42b1-bb7c-c928ed7f4159",
   "metadata": {},
   "source": [
    "### Calculating Embedding Cost with Tiktoken\n",
    "- We can find out about the cost. As an example, the embedding model (text-embedding-3-small) costs $0.00002/1k tokens.\n",
    "- We can count the tokens with the OpenAI **tiktoken** library (pip install tiktoken). tiktoken turns any text into tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc91ad0e-ff18-42c3-b972-622783f7b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can find out about the cost using the following formula.\n",
    "# cost = 0.00002 * len(tokens)/1000\n",
    "\n",
    "# We can use tiktoken to count the tokens\n",
    "import tiktoken\n",
    "\n",
    "# get a token encoder for the embedding model we're using.\n",
    "enc = tiktoken.encoding_for_model(\"text-embedding-3-small\")\n",
    "\n",
    "# for each document, encode it using the encoder, count the tokens by taking the length of the encoded docs, and sum the results.\n",
    "total_tokens = sum(len(enc.encode(text)) for text in documents)\n",
    "\n",
    "cost_per_1k_tokens = 0.00002\n",
    "\n",
    "print(\"Total tokens: \", total_tokens)\n",
    "print(\"Cost: \", cost_per_1k_tokens * total_tokens/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7602c3-dbf4-4501-b874-e0c9fb212522",
   "metadata": {},
   "source": [
    "## Querying and updating the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a287fa32-5c60-4505-b5c5-00d050690492",
   "metadata": {},
   "source": [
    "### Retrieve our collection\n",
    "- We must **specify the same embedding function** that was used when adding data to the collection. In this way Chroma will use the *same function* to create the **query vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc2e4c8-8acc-4795-8318-f0d463e6fe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "collection = client.get_collection(\n",
    "    name = \"netflix_titles\",\n",
    "    embedding_function=OpenAIEmbeddingFunction(api_key=\"...\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307d38a4-eea7-43fc-894c-d3d8eaae84dc",
   "metadata": {},
   "source": [
    "### Querying the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5401658-bf8f-4db1-a620-aa21cd48d33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = colection.query(\n",
    "    # this parameter is plural, so even if it's one item, we need to pass a list.\n",
    "    query_text=[\"movies where poeple sing a lot\"],\n",
    "    # number of items to retrieve\n",
    "    n_results=3\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fe6ca8-ebc9-4874-95b3-bacae950af36",
   "metadata": {},
   "source": [
    "### result\n",
    "\n",
    "- Query() returns s dictionary with multiple keys:\n",
    "    - ids: the id of the returned items\n",
    "        - A list of lists (an id for each document) e.g. 'id':[['s4068','s2213']] \n",
    "    - embeddings: the embeddings of the returned items\n",
    "    - documents: the source text of the returned items\n",
    "    - metadata: the metadatas of the the returned items\n",
    "    - distances: the distances of the returned items with the query text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fb37a6-163e-4482-a237-6f4771c9e462",
   "metadata": {},
   "source": [
    "### Update a collection\n",
    "- only include the fields that need to be updated. the rest of the fields will be unchanged.\n",
    "- collection will automatically create embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e32b1b-1459-45bc-a948-d6872bd1a84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.update(\n",
    "    ids=[\"id-1\", \"id-2\"],\n",
    "    documents=[\"New document 1\", \"New document 2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c57bae-8b7f-4ad0-9930-18662bd41605",
   "metadata": {},
   "source": [
    "- if we are not sure if the ids are present in the collection, use **collection.upsert()** function.\n",
    "- upsert will add the IDs if they are not present, and if they are present, it will update them.\n",
    "    - a combination of **add and update** methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cee7d1-fa01-4a1a-9088-b5e7a3b2ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.upsert(\n",
    "    ids=[\"id-1\", \"id-2\"],\n",
    "    documents=[\"New document 1\", \"New document 2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41288bc7-f751-49ce-891a-b0909659a37b",
   "metadata": {},
   "source": [
    "### Deleting a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd70fc1-cc59-4e8e-a4c3-251d030996b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.delete(\n",
    "    ids=[\"id-1\", \"id-2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e655aa21-521f-4cea-aea3-085c204d9362",
   "metadata": {},
   "source": [
    "### Deleting the whole database!! (careful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4c9bcd-fa7b-4a52-b23e-7577b8b6f3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55aa8f-15eb-492a-aaa8-2ff8d5424e31",
   "metadata": {},
   "source": [
    "## Multiple queries and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070fe542-509b-42d3-a800-a7add9c866ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_ids = ['s8170', 's8103']\n",
    "\n",
    "# retrieve the texts of our reference ids\n",
    "reference_texts = collection.get(ids=reference_ids)[\"documents\"]\n",
    "\n",
    "# we pass our reference texts as two queries\n",
    "result = collection.query(\n",
    "    query_texts = reference_texts,\n",
    "    # it means that return 3 results per query, so here we get two lists of three items\n",
    "    n_results=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a72a58-55aa-4608-bded-617c8acdca1a",
   "metadata": {},
   "source": [
    "### Adding metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4ae198a6-8ea2-444d-9f84-98450964ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use metadata to filter our query\n",
    "collection.update(ids=ids, metadatas=metadatas)\n",
    "\n",
    "result = collection.query(\n",
    "    query_texts = reference_texts,\n",
    "    n_results = 3,\n",
    "    # adding condition here\n",
    "    # we want to retrieve items whose metadata type is movie\n",
    "    where={\n",
    "        'type':'Movie'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e197ad28-2c92-46ca-9483-f911d11b0bc0",
   "metadata": {},
   "source": [
    "# Where filters (single or multiple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12254bdd-d812-4aba-bc15-4204ba8a4dfa",
   "metadata": {},
   "source": [
    "- use either of these cases for a where condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b174353b-4d3b-4d80-916f-c7f43ae9019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "where = {\n",
    "    'type':'Movie'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123b9bd8-93e6-487f-bff4-5194f1c3dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "where = {\n",
    "    \"type\" : {\n",
    "        \"$eq\": \"Movie\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f455fc3-f085-4038-bc0b-dee0445786a3",
   "metadata": {},
   "source": [
    "- There are different operator used to support different comparisions, including:\n",
    "    - \\$eq : equal to (string, int, float) \n",
    "    - \\$ne : not equal to (string, int, float) \n",
    "    - \\$gt : greater than (int, float) \n",
    "    - \\$gte : greater than or equal to (int, float) \n",
    "    - \\$lt : less than (int, float) \n",
    "    - \\$lte : less than or equal to (int, float)\n",
    "      \n",
    "- Where filters can be combined with **logical operators**\n",
    "    - \\$and\n",
    "    - \\$or: filter based on at least one condition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88601c0-8df1-4ca3-971f-bde42258aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "where = {\n",
    "    \"$and\" : [\n",
    "        {\"type\":\n",
    "            {\"$eq\":\"Movie\"}\n",
    "        },\n",
    "        {\"release_year\":\n",
    "            {\"$gt\": 2020}\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820dbd3b-9d3b-4174-b756-510a37df6127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
